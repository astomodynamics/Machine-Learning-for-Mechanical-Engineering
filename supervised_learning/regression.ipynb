{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SITN_0OLYD9"
      },
      "source": [
        "# Supervised Learning \n",
        "The assignment set is expected to perform supervised learning. In this assignemnt linear regression, Gaussian process regression, and Neural Networks are implemented.\n",
        "\n",
        "©Tomohiro Sasaki"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw4F49oELYEB"
      },
      "source": [
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iIMu8fCULYEC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from scipy.stats import multivariate_normal\n",
        "from scipy.spatial.distance import pdist, cdist, squareform\n",
        "\n",
        "# ML libraries for solution validation\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL6ZoJa2LYEC"
      },
      "source": [
        "## Setup and helper functions\n",
        "\n",
        "Before starting supervised learning, set up some useful functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVTbi9DnLYED"
      },
      "source": [
        "### Load CSV files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xTcYkjHYLYED"
      },
      "outputs": [],
      "source": [
        "def load_csv(data_file_path, class_index=-1):\n",
        "    \"\"\"\n",
        "    Load csv data in a numpy array.\n",
        "    Args:\n",
        "        data_file_path (str): path to data file.\n",
        "        class_index (int): slice index for data labels.\n",
        "    Returns:\n",
        "        features, classes as numpy arrays if class_index is specified,\n",
        "            otherwise all as nump array.\n",
        "    \"\"\"\n",
        "\n",
        "    handle = open(data_file_path, 'r')\n",
        "    contents = handle.read()\n",
        "    handle.close()\n",
        "    rows = contents.split('\\n')\n",
        "    \n",
        "    out = np.array([[float(i) for i in r.split(',')] for r in rows[1:-1] if r])\n",
        "\n",
        "    if(class_index == -1):\n",
        "        classes= out[:,class_index]\n",
        "        features = out[:,1:class_index]\n",
        "        return features, classes\n",
        "    elif(class_index == 0):\n",
        "        classes= out[:, class_index]\n",
        "        features = out[:, 1:]\n",
        "        return features, classes\n",
        "\n",
        "    else:\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3WImZA1YLYEE"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './HW2Dataset.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/0_/hzb6_bds081_7gkkfhwc6tk40000gn/T/ipykernel_11091/925477740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./HW2Dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/var/folders/0_/hzb6_bds081_7gkkfhwc6tk40000gn/T/ipykernel_11091/1005097216.py\u001b[0m in \u001b[0;36mload_csv\u001b[0;34m(data_file_path, class_index)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './HW2Dataset.csv'"
          ]
        }
      ],
      "source": [
        "X, y= load_csv('./Dataset.csv',-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2GbcBaiLYEE"
      },
      "source": [
        "### Split dataset into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LnI3F2CLYEF"
      },
      "outputs": [],
      "source": [
        "def split_dataset(X, y, shuffle=True, train_size=1.):\n",
        "    \"\"\"\n",
        "    Split dataset into training set and testing set\n",
        "    Args: \n",
        "        X (n x m array): dataset\n",
        "        y (float): label value\n",
        "        shuffle (Bool): shuffle after splitting\n",
        "        train_size (float): training set size\n",
        "    Returns:\n",
        "        X_train, X_test, y_train, y_test as numpy array\n",
        "    \"\"\"\n",
        "    m = X.shape[0]\n",
        "\n",
        "    m_train = int(train_size * m)\n",
        "    \n",
        "    ind_pool = [i for i in range(m)]\n",
        "    test_ind_pool = [i for i in range(m)]\n",
        "    \n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    train_ind_pool = []\n",
        "    \n",
        "    if shuffle:\n",
        "        random.shuffle(ind_pool)\n",
        "    \n",
        "    while len(X_train) < m_train:\n",
        "        ind = ind_pool.pop()\n",
        "        X_train.append(X[ind])\n",
        "        y_train.append(y[ind])\n",
        "        train_ind_pool.append(ind)\n",
        "        test_ind_pool.remove(ind)\n",
        "    \n",
        "    X_test = np.array([X[i] for i in test_ind_pool])\n",
        "    y_test = np.array([y[i] for i in test_ind_pool])\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Huz5E8OLYEF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_dataset(X, y, shuffle=True, train_size=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmNe-bhWLYEG"
      },
      "source": [
        "### Cross-validation\n",
        "\n",
        "To achieve a better fitted model of linear regression, we take a model validation technique called cross-validation.\n",
        "\n",
        "Here is the cross-validation step:\n",
        "1. Split the full dataset into a training set and a test set\n",
        "2. Split the training set into $k$ subsets\n",
        "3. For each of $k$ subsets\n",
        "   1. train a model using $k-1$ subsets\n",
        "   2. Compute the model error using the $k$ th subset\n",
        "4. Compare errors from Step 2. to errors computed using the full dataset\n",
        "5. If cross-validation errors are acceptable, build a model using the full training set\n",
        "6. Evaluate model error on the unsceen test set\n",
        "\n",
        "\n",
        "Cross-validation process is applied when Scikit-learn is used.\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "weWtprLcLYEG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAPYmd2wLYEG"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "(Multivariate) Linear regression is \n",
        "\n",
        "Basic equation is\n",
        "$$\n",
        "y = f(x) + \\varepsilon\\\\\n",
        "f(x) =  \\sum_{i=0}^{m} x_{i} \\quad {\\mathrm{where} ~x_0 = 1}\n",
        "$$\n",
        "Problem formulation is\n",
        "$$\n",
        "\n",
        "\\min \\mathrm{L S E} =\\min \\|{y}-{X} {w}\\|_{2}^{2}=\\min \\sum_{n=1}^{N}\\left[y^{(n)}-\\left(\\sum_{d=1}^{D} w_{d} X_{d}^{(n)}\\right)\\right]^{2}\n",
        "\\\\\n",
        "\\mathrm{where}~{y}=\\left[\\begin{array}{c}y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(N)}\\end{array}\\right] \\quad {X}=\\left[\\begin{array}{ccccc}1 & X_{1}^{(1)} & X_{2}^{(1)} & \\ldots & X_{D}^{(1)} \\\\ 1 & X_{1}^{(2)} & X_{2}^{(2)} & \\ldots & X_{D}^{(2)} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & X_{1}^{(N)} & X_{2}^{(N)} & \\ldots & X_{D}^{(N)}\\end{array}\\right] \\quad {w}=\\left[\\begin{array}{c}w_{0} \\\\ w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{D}\\end{array}\\right]\n",
        "$$\n",
        "\n",
        "Since this problem is a well-defined quadratic minimization problem, there is analytical solution if $X^\\mathrm{T}X$ exists.\n",
        "\n",
        "$$\n",
        "\\|y - Xw\\|^2_2 = y^{\\mathrm T} y - 2 y^{\\mathrm T} Xw + w^{\\mathrm T } X^{\\mathrm T} Xw \n",
        "$$\n",
        "Take the derivative with respect to the weight $w$, then we have the following:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\nabla_w  \\|y - Xw\\|^2_2 &= \\nabla_w \\left [y^{\\mathrm T} y - 2 y^{\\mathrm T} Xw + w^{\\mathrm T } X^{\\mathrm T} Xw \\right] \\\\\n",
        "&= -2 X^{\\mathrm T} (y - Xw) = 0\n",
        "\\end{aligned}\n",
        "$$\n",
        "Assuming $\\mathrm{rank}~X^{\\mathrm T}X = m$, then the solution of the minimization problem is:\n",
        "$$\n",
        "\\hat{w} = (X^\\mathrm{T} X)^{-1} X^{\\mathrm T} y\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWHkB0-_LYEG"
      },
      "source": [
        "## Linear Regression without regularization \n",
        "\n",
        "In linear regression without regularization model is directly fitted the solution we have ($\\hat{w} = (X^\\mathrm{T} X)^{-1} X^{\\mathrm T} y$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "vZ4AeCGJLYEH"
      },
      "outputs": [],
      "source": [
        "class LinearReg():\n",
        "    \"\"\" Class for Linear Regression without regularization \"\"\"\n",
        "    def __init__(self):\n",
        "        self._is_invertible = False\n",
        "        self._w = None\n",
        "        self._is_fitted = False\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        model fitting\n",
        "        \"\"\"\n",
        "        if np.linalg.matrix_rank(X.T @ X) == X.shape[1]:\n",
        "            self._is_invertible = True\n",
        "        if self._is_invertible:\n",
        "            H = np.ones((X.shape[0], X.shape[1]+1))\n",
        "            H[:,1:] = X\n",
        "            self._w = np.linalg.inv(H.T @ H) @ H.T @ y\n",
        "            self._is_fitted = True\n",
        "        else:\n",
        "            print(\"No solution exists or there exits infinite number of solution\")\n",
        "            return None\n",
        "\n",
        "    def model(self, x):\n",
        "        \"\"\"\n",
        "        computes the value of f(x)\n",
        "        \"\"\"\n",
        "        w = self._w\n",
        "        f = w[0]\n",
        "        for i in range(len(x)):\n",
        "            f += w[i+1] * x[i]\n",
        "        return f\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        predict the value of y using model and input dataset\n",
        "        \"\"\"\n",
        "        if self._is_fitted:\n",
        "            y = []\n",
        "            for x in X:\n",
        "                y.append(self.model(x))\n",
        "            return np.array(y)\n",
        "        else:\n",
        "            print(\"model is not fitted\")\n",
        "\n",
        "    def mean_squared_error(self, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        computes mean squared error\n",
        "        \"\"\"\n",
        "\n",
        "        return np.sum((y_test - y_pred)**2)/len(y_test)\n",
        "    \n",
        "    def r2_score(self, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        computes R squared score\n",
        "        \"\"\"\n",
        "        \n",
        "        return 1 - self.mean_squared_error(y_test, y_pred)/(np.sum((y_test - np.mean(y_pred))**2))*len(y_test)\n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-7OujfKLYEH"
      },
      "source": [
        "Fit the linear regression model,  predict values, and measure the performance\n",
        "\n",
        "Model fitting is validated through Cross-validation process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUUXkHwVLYEH",
        "outputId": "21d326db-8b61-4751-e38d-e430af7afe76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train prediction mean squared error is  65.1885936335363\n",
            "Train prediction R squared score is  0.8814199494517564\n",
            "Test prediction mean squared error is  62.25722386474444\n",
            "Test prediction R squared score is  0.8795291487490047\n"
          ]
        }
      ],
      "source": [
        "LR = LinearReg()\n",
        "LR.fit(X_train, y_train)\n",
        "y_train_pred = LR.predict(X_train)\n",
        "MSE_train = LR.mean_squared_error(y_train, y_train_pred)\n",
        "R2_train = LR.r2_score(y_train, y_train_pred)\n",
        "\n",
        "y_test_pred = LR.predict(X_test)\n",
        "MSE_test = LR.mean_squared_error(y_test, y_test_pred)\n",
        "R2_test = LR.r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Train prediction mean squared error is \", MSE_train)\n",
        "print(\"Train prediction R squared score is \", R2_train)\n",
        "\n",
        "print(\"Test prediction mean squared error is \", MSE_test)\n",
        "print(\"Test prediction R squared score is \", R2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DVlzKyfLYEI"
      },
      "source": [
        "## Linear Regression with regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjBk8PojLYEI"
      },
      "source": [
        "### Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRKzSK7QLYEI"
      },
      "source": [
        "Problem formulation for Ridge Regression is\n",
        "$$\n",
        "\n",
        "\\min \\|{y}-{X} {w}\\|_{2}^{2} + \\alpha \\|w\\|_2^2\n",
        "\n",
        "$$\n",
        "\n",
        "Since this problem is a well-defined quadratic minimization problem, there is analytical solution if $X^\\mathrm{T}X$ exists.\n",
        "\n",
        "The solution of the minimization problem is:\n",
        "$$\n",
        "\\hat{w} = (X^\\mathrm{T} X + \\alpha I)^{-1} X^{\\mathrm T} y\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5F8-juiPLYEJ"
      },
      "outputs": [],
      "source": [
        "class RidgeReg():\n",
        "    \"\"\" Class for Ridge Regression \"\"\"\n",
        "    def __init__(self, alpha=0.01):\n",
        "        self._is_invertible = False\n",
        "        self._w = None\n",
        "        self._is_fitted = False\n",
        "        self._alpha = alpha\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        model fitting\n",
        "        \"\"\"\n",
        "        if np.linalg.matrix_rank(X.T @ X) == X.shape[1]:\n",
        "            self._is_invertible = True\n",
        "        if self._is_invertible:\n",
        "            H = np.ones((X.shape[0], X.shape[1]+1))\n",
        "            H[:,1:] = X\n",
        "            self._w = np.linalg.inv(H.T @ H + self._alpha * np.eye(H.shape[1])) @ H.T @ y\n",
        "            self._is_fitted = True\n",
        "        else:\n",
        "            print(\"No solution exists or there exits infinite number of solution\")\n",
        "            return None\n",
        "\n",
        "    def model(self, x):\n",
        "        \"\"\"\n",
        "        computes the value of f(x)\n",
        "        \"\"\"\n",
        "        w = self._w\n",
        "        f = w[0]\n",
        "        for i in range(len(x)):\n",
        "            f += w[i+1] * x[i]\n",
        "        return f\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        predict the value of y using model and input dataset\n",
        "        \"\"\"\n",
        "        if self._is_fitted:\n",
        "            y = []\n",
        "            for x in X:\n",
        "                y.append(self.model(x))\n",
        "            return np.array(y)\n",
        "        else:\n",
        "            print(\"model is not fitted\")\n",
        "\n",
        "    def mean_squared_error(self, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        computes mean squared error\n",
        "        \"\"\"\n",
        "\n",
        "        return np.sum((y_test - y_pred)**2)/len(y_test)\n",
        "    \n",
        "    def r2_score(self, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        computes R squared score\n",
        "        \"\"\"\n",
        "        \n",
        "        return 1 - self.mean_squared_error(y_test, y_pred)/(np.sum((y_test - np.mean(y_pred))**2))*len(y_test)\n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH6MDdw0LYEJ"
      },
      "source": [
        "Fit the Ridge regression model,  predict values, and measure the performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aPXbtGzLYEJ",
        "outputId": "d67cf24a-bd79-4da7-b48b-ecdcfcb11e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train prediction mean squared error is  65.18910139349973\n",
            "Train prediction R squared score is  0.8814190290586765\n",
            "Test prediction mean squared error is  62.2411845075563\n",
            "Test prediction R squared score is  0.8795594519531477\n"
          ]
        }
      ],
      "source": [
        "RR= RidgeReg(alpha=0.5)\n",
        "RR.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = RR.predict(X_train)\n",
        "MSE_train = RR.mean_squared_error(y_train, y_train_pred)\n",
        "R2_train = RR.r2_score(y_train, y_train_pred)\n",
        "\n",
        "y_test_pred = RR.predict(X_test)\n",
        "MSE_test = RR.mean_squared_error(y_test, y_test_pred)\n",
        "R2_test = RR.r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Train prediction mean squared error is \", MSE_train)\n",
        "print(\"Train prediction R squared score is \", R2_train)\n",
        "\n",
        "print(\"Test prediction mean squared error is \", MSE_test)\n",
        "print(\"Test prediction R squared score is \", R2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbp_Lj4iLYEK"
      },
      "source": [
        "### LASSO Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmILjWm-LYEK"
      },
      "source": [
        "Problem formulation for LASSO Regression is\n",
        "$$\n",
        "\n",
        "\\min \\|{y}-{X} {w}\\|_{2}^{2} + \\alpha \\|w\\|_2^2\n",
        "\n",
        "$$\n",
        "\n",
        "Since this problem is a well-defined quadratic minimization problem, there is analytical solution if $X^\\mathrm{T}X$ exists.\n",
        "\n",
        "The solution of the minimization problem is:\n",
        "$$\n",
        "\\hat{w} = (X^\\mathrm{T} X + \\alpha I)^{-1} X^{\\mathrm T} y\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiXixbqHLYEK"
      },
      "source": [
        "--\n",
        "Ridge has the best score compared to linear and LASSO regressions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fENeUvQLYEK"
      },
      "source": [
        "## validate via scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H13hmckaLYEK"
      },
      "source": [
        "#### Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmhaA_2xLYEL",
        "outputId": "29eec2ca-5686-4768-d10e-4a75121f0dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MSE is 65.18859383360724\n",
            "Training R2 score is  0.8814199490878212\n",
            "Testing MSE is 62.25695238649217\n",
            "Testing R2 score is  0.8794944427357075\n"
          ]
        }
      ],
      "source": [
        "rr = Ridge(alpha=0.01)\n",
        "rr.fit(X_train, y_train) \n",
        "\n",
        "pred_train_rr= rr.predict(X_train)\n",
        "\n",
        "print(\"Training MSE is\", mean_squared_error(y_train,pred_train_rr))\n",
        "print(\"Training R2 score is \",r2_score(y_train, pred_train_rr))\n",
        "\n",
        "pred_test_rr= rr.predict(X_test)\n",
        "print(\"Testing MSE is\", mean_squared_error(y_test,pred_test_rr))\n",
        "print(\"Testing R2 score is \", r2_score(y_test, pred_test_rr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90vOA_d5LYEL"
      },
      "source": [
        "## Cross-validation with Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtH-xFZ9LYEL",
        "outputId": "4b7f516b-51d7-4fdc-ad10-37a2aa310d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.88 accuracy with a standard deviation of 0.00\n"
          ]
        }
      ],
      "source": [
        "scores = cross_val_score(rr, X_train, y_train, scoring='r2', cv=5)\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSi1WdBOLYEM"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1cK2jzhLYEM"
      },
      "source": [
        "# Gaussian Process Regression\n",
        "\n",
        "Gaussian process regression is a flexible class of nonparametric machine learning model commonly used for model spatial and time series data. The definition of gaussian process is the following: A Gaussian process is a collection of random variables, any finite number of which have a joint Gaussian distribution. We write the gaussian process in math as\n",
        "$$\n",
        "f(x) \\sim \\mathcal{G P}\\left(m(\\mathbf{x}), k\\left(\\mathbf{x}, \\mathbf{x}^{\\prime}\\right)\\right)\n",
        "$$\n",
        "where $m(\\cdot)$ is the mean function and $k(\\cdot,\\cdot)$ is the covariance function.\n",
        "\n",
        "Predictions for test points $f_*$ for given trainting points $f$ requires a multivariate conditional density given as\n",
        "$$\n",
        "p(f_*|f) = \\mathcal{N} (\\mu,\\Sigma)\n",
        "$$\n",
        "\n",
        "In this assignment we use the exponential quadratic covariance function as an example. The covariance function specifies the covariance between pairs of random variables\n",
        "$$\n",
        "\\operatorname{cov}\\left(f\\left(\\mathbf{x}_{i}\\right), f\\left(\\mathbf{x}_{j}\\right)\\right)=k\\left(\\mathbf{x}_{i}, \\mathbf{x}_{j}\\right)=\\exp \\left(-\\frac{1}{2}\\left \\|\\mathbf{x}_{i}-\\mathbf{x}_{j}\\right\\|_2^{2}\\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "XwQXNPiwLYEM"
      },
      "outputs": [],
      "source": [
        "from scipy.linalg import cholesky, cho_solve, solve_triangular\n",
        "\n",
        "class GausProcReg():\n",
        "    \"\"\" Class for Linear Regression without regularization \"\"\"\n",
        "    def __init__(self, alpha=1e-5, ell=None, normalize_y=True):\n",
        "        self.alpha = alpha\n",
        "        self.ell = ell\n",
        "        self.normalize_y = normalize_y\n",
        "\n",
        "\n",
        "    def kernel(self, X, Y=None, kernel=\"RBF\"):\n",
        "        \"\"\" \n",
        "        Define a covariance function, kernel function\n",
        "        \"\"\"\n",
        "        alpha =  self.alpha\n",
        "        ell = self.ell\n",
        "        if ell == None:\n",
        "            ell = len(X)\n",
        "        \n",
        "        if kernel == \"RBF\":\n",
        "            # return alpha*np.exp(-0.5*(np.linalg.norm(x1-x2)/ell)**2)\n",
        "            X = np.atleast_2d(X)\n",
        "        \n",
        "            if Y is None:\n",
        "                dists = pdist(X, metric=\"sqeuclidean\")\n",
        "                K = np.exp(-0.5 * dists)\n",
        "                # convert from upper-triangular matrix to square matrix\n",
        "                K = squareform(K)\n",
        "                np.fill_diagonal(K, 1)\n",
        "            else:\n",
        "                dists = cdist(X, Y, metric=\"sqeuclidean\")\n",
        "                K = np.exp(-0.5 * dists)\n",
        "            return K\n",
        "\n",
        "\n",
        "    def fit(self, X, y, y_std=None):\n",
        "        \"\"\"\n",
        "        model fitting\n",
        "        \"\"\"\n",
        "        \n",
        "        if self.normalize_y:\n",
        "            self._y_train_mean = np.mean(y, axis=0)\n",
        "            self._y_train_std = np.std(y, axis=0)\n",
        "            y = (y - self._y_train_mean) / self._y_train_std\n",
        "        else:\n",
        "            shape_y_stats = (y.shape[1],) if y.ndim == 2 else 1\n",
        "            self._y_train_mean = np.zeros(shape=shape_y_stats)\n",
        "            self._y_train_std = np.ones(shape=shape_y_stats)\n",
        "\n",
        "        Kff = self.kernel(X)\n",
        "\n",
        "        self.X_train_ = np.copy(X)\n",
        "        self.y_train_ = np.copy(y) \n",
        "\n",
        "        try:\n",
        "            self.L_ = cholesky(Kff, lower=True, check_finite=False)\n",
        "        except np.linalg.LinAlgError as exc:\n",
        "            exc.args = (\n",
        "                \"K matrix is not positive definite\") \n",
        "            raise\n",
        "        \n",
        "        self.alpha_ = cho_solve(\n",
        "            (self.L_, True),\n",
        "            self.y_train_,\n",
        "            check_finite=False,\n",
        "        )\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        predict the value of y using model and input dataset\n",
        "        \"\"\"\n",
        "        if self.alpha_ is not None:\n",
        "            m = len(X)\n",
        "            Ksf = self.kernel(X, self.X_train_)\n",
        "            # compute posterior mean\n",
        "            y_mean = Ksf @ self.alpha_\n",
        "\n",
        "            # undo normalization\n",
        "            y_mean = self._y_train_std * y_mean + self._y_train_mean\n",
        "            \n",
        "            V = solve_triangular(\n",
        "                self.L_, Ksf.T, lower=True, check_finite=False\n",
        "            )\n",
        "\n",
        "            Kss = self.kernel(X)\n",
        "\n",
        "            # compute posterior covariance\n",
        "            y_cov = np.zeros((m,m))\n",
        "            y_cov = Kss - V.T @ V\n",
        "\n",
        "            # undo normalisation\n",
        "            y_cov = np.outer(y_cov, self._y_train_std**2).reshape(*y_cov.shape, -1)\n",
        "\n",
        "            if y_cov.shape[2] == 1:\n",
        "                y_cov = np.squeeze(y_cov, axis=2)\n",
        "\n",
        "            # compute log likelihood (not always necessary)\n",
        "            # log_like = -1/2 * y @ np.linalg.inv(Kff + sigma**2 * np.eye(m)) @ y \\\n",
        "            #         -1/2 * np.log(np.linalg.det(Kff + sigma**2 * np.eye(m))) \\\n",
        "            #         - m/2 * np.log(2 * np.pi) \n",
        "\n",
        "            return y_mean, y_cov\n",
        "        else:\n",
        "            print(\"model is not fitted\")\n",
        "\n",
        "    def mean_squared_error(self, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        computes mean squared error\n",
        "        \"\"\"\n",
        "\n",
        "        return np.sum((y_test - y_pred)**2)/len(y_test)\n",
        "    \n",
        "    def r2_score(self, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        computes R squared score\n",
        "        \"\"\"\n",
        "        \n",
        "        return 1 - self.mean_squared_error(y_test, y_pred)/(np.sum((y_test - np.mean(y_pred))**2))*len(y_test)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkvvJ9cPLYEN",
        "outputId": "e3909e2f-519a-4289-9118-037b732bf254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train prediction mean squared error is  7.082123115282065e-26\n",
            "Train prediction R squared score is  0.8814190290586765\n",
            "Test prediction mean squared error is  32.10426073921217\n",
            "Test prediction R squared score is  0.9382362916233387\n"
          ]
        }
      ],
      "source": [
        "GPR= GausProcReg(alpha=1e-6, ell=1.,normalize_y=False)\n",
        "GPR.fit(X_train, y_train)\n",
        "\n",
        "y_train_mean, y_train_cov = GPR.predict(X_train)\n",
        "\n",
        "MSE_train = GPR.mean_squared_error(y_train, y_train_mean)\n",
        "# R2_train = GPR.r2_score(y_train, y_train_pred)\n",
        "\n",
        "y_test_mean, y_test_cov = GPR.predict(X_test)\n",
        "MSE_test = GPR.mean_squared_error(y_test, y_test_mean)\n",
        "R2_test = GPR.r2_score(y_test, y_test_mean)\n",
        "\n",
        "print(\"Train prediction mean squared error is \", MSE_train)\n",
        "print(\"Train prediction R squared score is \", R2_train)\n",
        "\n",
        "print(\"Test prediction mean squared error is \", MSE_test)\n",
        "print(\"Test prediction R squared score is \", R2_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxTM6b_zLYEP"
      },
      "source": [
        "### Scikit-learn validation (Compare self-made Gaussian Process Regression with Scikit-learn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObGrGGbmLYEP",
        "outputId": "65cc0799-5087-4997-8cce-6cc4da474b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lengthscale: RationalQuadratic(alpha=0.0297, length_scale=4.33)\n"
          ]
        }
      ],
      "source": [
        "# Construction of Sklearn's Regression and Selection of the Kernel\n",
        "# kernel = RBF()\n",
        "# kernel = Matern()\n",
        "kernel = RationalQuadratic()\n",
        "gp_regressor = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
        "gp_regressor.fit(X_train, y_train)\n",
        "print(f\"Lengthscale: {gp_regressor.kernel_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmQUZp8iLYEP",
        "outputId": "09cf3596-27c1-478e-b35d-f3013fdd07b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MSE is 3.890915468082337e-07\n",
            "Training R2 score is  0.9999999992922306\n",
            "Testing MSE is 4.86918999100871\n",
            "Testing R2 score is  0.9905751176246216\n"
          ]
        }
      ],
      "source": [
        "pred_train_gpr, y_pred_std = gp_regressor.predict(X_train, return_std=True)\n",
        "pred_test_gpr, y_pred_std = gp_regressor.predict(X_test, return_std=True)\n",
        "\n",
        "print(\"Training MSE is\", mean_squared_error(y_train, pred_train_gpr))\n",
        "print(\"Training R2 score is \",r2_score(y_train, pred_train_gpr))\n",
        "\n",
        "print(\"Testing MSE is\", mean_squared_error(y_test, pred_test_gpr))\n",
        "print(\"Testing R2 score is \", r2_score(y_test, pred_test_gpr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtqRR_ClU7Kh"
      },
      "source": [
        "## Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hknik9IWU6sr",
        "outputId": "35250908-2531-420a-8937-13e454546c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.99 accuracy with a standard deviation of 0.00\n"
          ]
        }
      ],
      "source": [
        "scores = cross_val_score(gp_regressor, X_train, y_train, scoring='r2', cv=5)\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym68iZXxLYEQ"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0H33CHsLYEQ"
      },
      "source": [
        "# Neural Networks (No self-made class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9xmiNxvLYER"
      },
      "source": [
        "##  Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "-btKnLH4LYER",
        "outputId": "58ae48c6-3854-4fca-81b3-da703b74d080"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(learning_rate=&#x27;adaptive&#x27;, max_iter=1000, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(learning_rate=&#x27;adaptive&#x27;, max_iter=1000, random_state=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPRegressor(learning_rate='adaptive', max_iter=1000, random_state=1)"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn_regressor = MLPRegressor(\n",
        "    hidden_layer_sizes=(100,), \n",
        "    activation='relu',\n",
        "    solver='adam', \n",
        "    batch_size='auto', \n",
        "    learning_rate='adaptive',\n",
        "    learning_rate_init=0.001,\n",
        "    random_state=1, \n",
        "    max_iter=1000)\n",
        "nn_regressor.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRtznMbiY2tQ",
        "outputId": "701e2dfe-97fe-414f-9729-a5c1d6a9bf97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MSE is 3.318263556105546\n",
            "Training R2 score is  0.9939639768511134\n",
            "Testing MSE is 3.9648184253411642\n",
            "Testing R2 score is  0.992325633756831\n"
          ]
        }
      ],
      "source": [
        "pred_train_nn = nn_regressor.predict(X_train)\n",
        "pred_test_nn = nn_regressor.predict(X_test)\n",
        "\n",
        "print(\"Training MSE is\", mean_squared_error(y_train, pred_train_nn))\n",
        "print(\"Training R2 score is \",r2_score(y_train, pred_train_nn))\n",
        "\n",
        "print(\"Testing MSE is\", mean_squared_error(y_test, pred_test_nn))\n",
        "print(\"Testing R2 score is \", r2_score(y_test, pred_test_nn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A3mF-3XZ0da"
      },
      "source": [
        "## Cross-validation (Neural Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRrUXyeAZ04P",
        "outputId": "b47121a5-47b0-4e34-9cfc-48260afb24ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9921 accuracy with a standard deviation of 0.00\n"
          ]
        }
      ],
      "source": [
        "scores = cross_val_score(nn_regressor, X_train, y_train, scoring='r2', cv=5)\n",
        "print(\"%0.4f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIY6skK9LYER"
      },
      "source": [
        "## Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "63RlQe_1LYER",
        "outputId": "f957ed6b-45c2-480f-84dc-1f0a5eb6be8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 14.56\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Convert to 2D PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "# Define the model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(15, 30, bias=False),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30, 10, bias=False),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 4, bias=False),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4, 1, bias=False)\n",
        ")\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_fn = nn.MSELoss() \n",
        "learning_rate = 0.0001\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Setup epochs and batch size\n",
        "n_epochs = 100  \n",
        "batch_size = 10  \n",
        "batch_start = torch.arange(0, len(X_train), batch_size)\n",
        "\n",
        "\n",
        "# learning setup\n",
        "best_mse = np.inf   # init to infinity\n",
        "best_weights = None\n",
        "history = []\n",
        " \n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        \n",
        "        for start in bar:\n",
        "            # take a batch\n",
        "            X_batch = X_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "\n",
        "            # forward pass\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # print progress\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "            \n",
        "    # evaluate accuracy at end of each epoch\n",
        "    model.eval()\n",
        "    y_pred = model(X_test)\n",
        "    mse = loss_fn(y_pred, y_test)\n",
        "    mse = float(mse)\n",
        "    history.append(mse)\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        " \n",
        "# restore model and return best accuracy\n",
        "model.load_state_dict(best_weights)\n",
        "print(\"MSE: %.2f\" % best_mse)\n",
        "plt.plot(history)\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4626afe764c677b78b8258e2e71fbdf1da993c1945f1dd8e48f8920ec3d145ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
